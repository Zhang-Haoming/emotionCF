{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Emotion CF A Python package for collaborative filtering on emotion datasets Installation pip install git+https://github.com/cosanlab/emotionCF.git Example Usage Create a subject by item matrix The emotionCF toolbox operates on pandas dataframes that contain ratings for each subject by each item. There is a function to easily convert a long format pandas dataframe that contains ['Subject','Item','Rating] as columns, create_sub_by_item_matrix() . These data can be passed onto any cf class. from emotioncf.data import create_sub_by_item_matrix ratings = create_sub_by_item_matrix ( long_format_df ) Intialize a cf instance Initialize a new cf instance by passing in the subject by item ratings pandas DataFrame from emotioncf.cf import KNN cf = KNN(ratings) Split Data into Train and Test It is easy to split a ratings matrix into training and test items using the split_train_test() method. It creates a binary mask called .train_mask field that indicates the training values. cf . split_train_test ( n_train_items = 50 ) Estimate Model Each model can be estimated using the fit() method cf . fit () Predict New Ratings Missing data from the matrix can then be filled in using the predict() method. This creates a pandas dataframe of the predicted subject by item matrix in the predicted_ratings field. cf . predict () Evaluate Model Predictions There are several methods to aid in evaluating the performance of the model, including overall mean squared error get_mse() , overall correlation get_corr() , and correlation for each subject get_sub_corr() . Each method can be run on all of the data using the default 'all' flag. If the data has been split into test and training, it is also possible to explicitly evaluate how well the model performs on the 'test' and 'train' data. cf . get_mse ( 'all' ) cf . get_corr ( 'test' ) cf . get_sub_corr ( 'train' ) Mean An easy control model for collaborative filtering is to demonstrate how well the models perform over simply using the item means. We initalize a class instance and then the model can be estimated and new ratings predicted. We can get the overall mean squared error on the predicted ratings. from emotioncf.cf import Mean cf = Mean ( ratings ) cf . fit () cf . predict () cf . get_mse ( 'all' ) K-Nearest Neighbors EmotionCF uses a standard API to estimate and predict data. Though the KNN approach is not technically a model, we still use the fit method to estimate data. This calculates a similarity matrix between subjects using ['correlation','cosine'] methods. We can then predict the left out ratings using the top k nearest neighbors. We can evaluate how well the model works for all data points using get_corr() and get_mse() methods. We can also get the correlation for each subject's indivdiual data using get_sub_corr() method. So far we have found that this method does not perform well when there aren't many overlapping samples across items and users. from emotioncf.cf import KNN cf = KNN ( ratings ) cf . split_train_test ( n_train_items = 20 ) cf . fit ( metric = 'pearson' ) cf . predict ( k = 10 ) cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . get_sub_corr ( 'test' ) Non-negative matrix factorization using stochastic gradient descent Here we initialize a new class instance and split the data into 20 training and 80 test items per subject. We fit the model using 100 iterations. Can pass in optional regularization parameters and a learning rate for the update function. The model is then used to predict the left out ratings. We can get the overall model MSE and correlation value on the test ratings. We can also make a quick plot of the results. As indicated by the name, this method does not work with data that includes negative numbers. from emotioncf.cf import NNMF_sgd cf = NNMF_sgd ( ratings ) cf . split_train_test ( n_train_items = 20 ) cf . fit ( n_iterations = 100 , user_fact_reg = 0 , item_fact_reg = 0 , user_bias_reg = 0 , item_bias_reg = 0 , learning_rate =. 001 ) cf . predict () cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . plot_predictions () Non-negative matrix factorization using multiplicative updating Similarly, we can fit a different NNMF model that uses multiplicative updating with the NNMF_multiplicative class. from emotioncf.cf import NNMF_multiplicative cf = NNMF_multiplicative ( ratings ) cf . split_train_test ( n_train_items = 20 ) cf . fit ( max_iterations = 200 ) cf . predict () cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . plot_predictions () Working with Time-Series Data This tool has also been designed to work with timeseries data. For example, cf instances can be downsampled across items, where items refers to time samples. You must specify the sampling_freq of the data, and the target , where target must have a target_type of ['hz','samples','seconds']. Downsampling is performed by averaging over bin windows. In this example we downsample a dataset from 10hz to 5hz. cf . downsample ( sampling_freq = 10 , target = 5 , target_type = 'hz' ) It is also possible to leverage presumed autocorrelation when training models by using the dilate_ts_n_samples=n_samples keyword. This flag will convolve a boxcar regressor with each subject's sample from cf.train_mask n_samples . The dilation will be centered on each sample. The intuition here is that if a subject rates an item at a given time point, say '50', they likely will have rated time points immediately preceding and following similarly (e.g., [50,50,50]). This is due to autocorrelation in the data. More presumed autocorrelation will likely benefit from a higher number of samples being selected. This will allow time series that are sparsely sampled to be estimated more accurately. cf = NNMF_sgd ( ratings ) mask = cf . train_mask cf . split_train_test ( n_train_items = 20 ) cf . fit ( n_iterations = 100 , user_fact_reg = 1.0 , item_fact_reg = 0.001 , user_bias_reg = 0 , item_bias_reg = 0 , learning_rate =. 001 , dilate_ts_n_samples = 20 ) cf . predict () cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . plot_predictions ()","title":"Home"},{"location":"#emotion-cf","text":"A Python package for collaborative filtering on emotion datasets","title":"Emotion CF"},{"location":"#installation","text":"pip install git+https://github.com/cosanlab/emotionCF.git","title":"Installation"},{"location":"#example-usage","text":"","title":"Example Usage"},{"location":"#create-a-subject-by-item-matrix","text":"The emotionCF toolbox operates on pandas dataframes that contain ratings for each subject by each item. There is a function to easily convert a long format pandas dataframe that contains ['Subject','Item','Rating] as columns, create_sub_by_item_matrix() . These data can be passed onto any cf class. from emotioncf.data import create_sub_by_item_matrix ratings = create_sub_by_item_matrix ( long_format_df )","title":"Create a subject by item matrix"},{"location":"#intialize-a-cf-instance","text":"Initialize a new cf instance by passing in the subject by item ratings pandas DataFrame from emotioncf.cf import KNN cf = KNN(ratings)","title":"Intialize a cf instance"},{"location":"#split-data-into-train-and-test","text":"It is easy to split a ratings matrix into training and test items using the split_train_test() method. It creates a binary mask called .train_mask field that indicates the training values. cf . split_train_test ( n_train_items = 50 )","title":"Split Data into Train and Test"},{"location":"#estimate-model","text":"Each model can be estimated using the fit() method cf . fit ()","title":"Estimate Model"},{"location":"#predict-new-ratings","text":"Missing data from the matrix can then be filled in using the predict() method. This creates a pandas dataframe of the predicted subject by item matrix in the predicted_ratings field. cf . predict ()","title":"Predict New Ratings"},{"location":"#evaluate-model-predictions","text":"There are several methods to aid in evaluating the performance of the model, including overall mean squared error get_mse() , overall correlation get_corr() , and correlation for each subject get_sub_corr() . Each method can be run on all of the data using the default 'all' flag. If the data has been split into test and training, it is also possible to explicitly evaluate how well the model performs on the 'test' and 'train' data. cf . get_mse ( 'all' ) cf . get_corr ( 'test' ) cf . get_sub_corr ( 'train' )","title":"Evaluate Model Predictions"},{"location":"#mean","text":"An easy control model for collaborative filtering is to demonstrate how well the models perform over simply using the item means. We initalize a class instance and then the model can be estimated and new ratings predicted. We can get the overall mean squared error on the predicted ratings. from emotioncf.cf import Mean cf = Mean ( ratings ) cf . fit () cf . predict () cf . get_mse ( 'all' )","title":"Mean"},{"location":"#k-nearest-neighbors","text":"EmotionCF uses a standard API to estimate and predict data. Though the KNN approach is not technically a model, we still use the fit method to estimate data. This calculates a similarity matrix between subjects using ['correlation','cosine'] methods. We can then predict the left out ratings using the top k nearest neighbors. We can evaluate how well the model works for all data points using get_corr() and get_mse() methods. We can also get the correlation for each subject's indivdiual data using get_sub_corr() method. So far we have found that this method does not perform well when there aren't many overlapping samples across items and users. from emotioncf.cf import KNN cf = KNN ( ratings ) cf . split_train_test ( n_train_items = 20 ) cf . fit ( metric = 'pearson' ) cf . predict ( k = 10 ) cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . get_sub_corr ( 'test' )","title":"K-Nearest Neighbors"},{"location":"#non-negative-matrix-factorization-using-stochastic-gradient-descent","text":"Here we initialize a new class instance and split the data into 20 training and 80 test items per subject. We fit the model using 100 iterations. Can pass in optional regularization parameters and a learning rate for the update function. The model is then used to predict the left out ratings. We can get the overall model MSE and correlation value on the test ratings. We can also make a quick plot of the results. As indicated by the name, this method does not work with data that includes negative numbers. from emotioncf.cf import NNMF_sgd cf = NNMF_sgd ( ratings ) cf . split_train_test ( n_train_items = 20 ) cf . fit ( n_iterations = 100 , user_fact_reg = 0 , item_fact_reg = 0 , user_bias_reg = 0 , item_bias_reg = 0 , learning_rate =. 001 ) cf . predict () cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . plot_predictions ()","title":"Non-negative matrix factorization using stochastic gradient descent"},{"location":"#non-negative-matrix-factorization-using-multiplicative-updating","text":"Similarly, we can fit a different NNMF model that uses multiplicative updating with the NNMF_multiplicative class. from emotioncf.cf import NNMF_multiplicative cf = NNMF_multiplicative ( ratings ) cf . split_train_test ( n_train_items = 20 ) cf . fit ( max_iterations = 200 ) cf . predict () cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . plot_predictions ()","title":"Non-negative matrix factorization using multiplicative updating"},{"location":"#working-with-time-series-data","text":"This tool has also been designed to work with timeseries data. For example, cf instances can be downsampled across items, where items refers to time samples. You must specify the sampling_freq of the data, and the target , where target must have a target_type of ['hz','samples','seconds']. Downsampling is performed by averaging over bin windows. In this example we downsample a dataset from 10hz to 5hz. cf . downsample ( sampling_freq = 10 , target = 5 , target_type = 'hz' ) It is also possible to leverage presumed autocorrelation when training models by using the dilate_ts_n_samples=n_samples keyword. This flag will convolve a boxcar regressor with each subject's sample from cf.train_mask n_samples . The dilation will be centered on each sample. The intuition here is that if a subject rates an item at a given time point, say '50', they likely will have rated time points immediately preceding and following similarly (e.g., [50,50,50]). This is due to autocorrelation in the data. More presumed autocorrelation will likely benefit from a higher number of samples being selected. This will allow time series that are sparsely sampled to be estimated more accurately. cf = NNMF_sgd ( ratings ) mask = cf . train_mask cf . split_train_test ( n_train_items = 20 ) cf . fit ( n_iterations = 100 , user_fact_reg = 1.0 , item_fact_reg = 0.001 , user_bias_reg = 0 , item_bias_reg = 0 , learning_rate =. 001 , dilate_ts_n_samples = 20 ) cf . predict () cf . get_mse ( 'test' ) cf . get_corr ( 'test' ) cf . plot_predictions ()","title":"Working with Time-Series Data"},{"location":"development/","text":"Development To develop this package or its documentation locally you will need to install a few extra dependencies. Installation pip install -r requirements-dev.txt Testing To run tests just call pytest from the root of this repository. New tests can be added in emotioncf/tests/ . Documentation Documentation is built with mkdocs using the mkdocs material theme and mkdocstrings extension. Live server After installation above, simply run mkdocs serve this the project root to start a hot-reloading server of the documentation at http://localhost:8000 . To alter the layout of the docs site adjust settings in mkdocs.yml . To add or edit pages simply create markdown files within the docs/ folder. Deploying You can use the mkdocs gh-deploy command in order to build and push the documentation site to the github-pages branch of this repo.","title":"Development"},{"location":"development/#development","text":"To develop this package or its documentation locally you will need to install a few extra dependencies.","title":"Development"},{"location":"development/#installation","text":"pip install -r requirements-dev.txt","title":"Installation"},{"location":"development/#testing","text":"To run tests just call pytest from the root of this repository. New tests can be added in emotioncf/tests/ .","title":"Testing"},{"location":"development/#documentation","text":"Documentation is built with mkdocs using the mkdocs material theme and mkdocstrings extension.","title":"Documentation"},{"location":"development/#live-server","text":"After installation above, simply run mkdocs serve this the project root to start a hot-reloading server of the documentation at http://localhost:8000 . To alter the layout of the docs site adjust settings in mkdocs.yml . To add or edit pages simply create markdown files within the docs/ folder.","title":"Live server"},{"location":"development/#deploying","text":"You can use the mkdocs gh-deploy command in order to build and push the documentation site to the github-pages branch of this repo.","title":"Deploying"},{"location":"api/cf/","text":"cf Classes that perform various types of collaborative filtering BaseCF Base Collaborative Filtering Class downsample ( self , sampling_freq = None , target = None , target_type = 'samples' ) Downsample rating matrix to a new target frequency or number of samples using averaging. Parameters: Name Type Description Default sampling_freq int/float Sampling frequency of data None target int/float downsampling target None target_type str type of target can be [samples,seconds,hz] 'samples' Source code in emotioncf/cf.py def downsample ( self , sampling_freq = None , target = None , target_type = \"samples\" ): \"\"\"Downsample rating matrix to a new target frequency or number of samples using averaging. Args: sampling_freq (int/float): Sampling frequency of data target (int/float): downsampling target target_type (str): type of target can be [samples,seconds,hz] \"\"\" if sampling_freq is None : raise ValueError ( \"Please specify the sampling frequency of the ratings data.\" ) if target is None : raise ValueError ( \"Please specify the downsampling target.\" ) if target_type is None : raise ValueError ( \"Please specify the type of target to downsample to [samples,seconds,hz].\" ) def ds ( ratings , sampling_freq = sampling_freq , target = None , target_type = \"samples\" ): if target_type == \"samples\" : n_samples = target elif target_type == \"seconds\" : n_samples = target * sampling_freq elif target_type == \"hz\" : n_samples = sampling_freq / target else : raise ValueError ( 'Make sure target_type is \"samples\", \"seconds\", or \"hz\".' ) ratings = ratings . T idx = np . sort ( np . repeat ( np . arange ( 1 , ratings . shape [ 0 ] / n_samples , 1 ), n_samples ) ) if ratings . shape [ 0 ] > len ( idx ): idx = np . concatenate ( [ idx , np . repeat ( idx [ - 1 ] + 1 , ratings . shape [ 0 ] - len ( idx ))] ) return ratings . groupby ( idx ) . mean () . T self . ratings = ds ( self . ratings , sampling_freq = sampling_freq , target = target , target_type = target_type , ) if self . is_mask : self . train_mask = ds ( self . train_mask , sampling_freq = sampling_freq , target = target , target_type = target_type , ) self . train_mask . loc [:, :] = self . train_mask > 0 self . masked_ratings = ds ( self . masked_ratings , sampling_freq = sampling_freq , target = target , target_type = target_type , ) if self . is_mask_dilated : self . dilated_mask = ds ( self . dilated_mask , sampling_freq = sampling_freq , target = target , target_type = target_type , ) self . dilated_mask . loc [:, :] = self . dilated_mask > 0 if self . is_predict : self . predicted_ratings = ds ( self . predicted_ratings , sampling_freq = sampling_freq , target = target , target_type = target_type , ) get_corr ( self , data = 'all' ) Get overall correlation for predicted compared to actual for all items and subjects. Parameters: Name Type Description Default data str Get correlation on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description r (float) Correlation Source code in emotioncf/cf.py def get_corr ( self , data = \"all\" ): \"\"\"Get overall correlation for predicted compared to actual for all items and subjects. Args: data (str): Get correlation on 'all' data, the 'training' data, or the 'test' data Returns: r (float): Correlation \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) actual , pred = self . _retrieve_predictions ( data ) return pearsonr ( actual , pred )[ 0 ] get_mse ( self , data = 'all' ) Get overall mean squared error for predicted compared to actual for all items and subjects. Parameters: Name Type Description Default data str Get mse on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description mse (float) mean squared error Source code in emotioncf/cf.py def get_mse ( self , data = \"all\" ): \"\"\"Get overall mean squared error for predicted compared to actual for all items and subjects. Args: data (str): Get mse on 'all' data, the 'training' data, or the 'test' data Returns: mse (float): mean squared error \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) actual , pred = self . _retrieve_predictions ( data ) return np . mean (( pred - actual ) ** 2 ) get_sub_corr ( self , data = 'all' ) Calculate observed/predicted correlation for each subject in matrix Parameters: Name Type Description Default data str Get correlation on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description r (float) Correlation Source code in emotioncf/cf.py def get_sub_corr ( self , data = \"all\" ): \"\"\"Calculate observed/predicted correlation for each subject in matrix Args: data (str): Get correlation on 'all' data, the 'training' data, or the 'test' data Returns: r (float): Correlation \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) r = [] # Note: the following mask prevents NaN values from being passed to `pearsonr()`. # However, it does not guaratee that no correlation values will be NaN, e.g. if only one # rating for a given subject is non-null in both test and train groups for a given # dataset, or variance is otherwise zero. if data == \"all\" : noNanMask = ( ~ np . isnan ( self . ratings )) & ( ~ np . isnan ( self . predicted_ratings )) for i in self . ratings . index : r . append ( pearsonr ( self . ratings . loc [ i , :][ noNanMask . loc [ i , :]], self . predicted_ratings . loc [ i , :][ noNanMask . loc [ i , :]], )[ 0 ] ) elif self . is_mask : if data == \"training\" : noNanMask = ( ~ np . isnan ( self . masked_ratings )) & ( ~ np . isnan ( self . predicted_ratings ) ) if self . is_mask_dilated : for i in self . masked_ratings . index : r . append ( pearsonr ( self . masked_ratings . loc [ i , self . dilated_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], self . predicted_ratings . loc [ i , self . dilated_mask . loc [ i , :] ][ noNanMask . loc [ i , :]], )[ 0 ] ) else : for i in self . masked_ratings . index : r . append ( pearsonr ( self . masked_ratings . loc [ i , self . train_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], self . predicted_ratings . loc [ i , self . train_mask . loc [ i , :] ][ noNanMask . loc [ i , :]], )[ 0 ] ) else : # test noNanMask = ( ~ np . isnan ( self . ratings )) & ( ~ np . isnan ( self . predicted_ratings ) ) for i in self . masked_ratings . index : r . append ( pearsonr ( self . ratings . loc [ i , ~ self . train_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], self . predicted_ratings . loc [ i , ~ self . train_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], )[ 0 ] ) else : raise ValueError ( \"Must run split_train_test() before using this option.\" ) return np . array ( r ) get_sub_mse ( self , data = 'all' ) Calculate observed/predicted mse for each subject in matrix Parameters: Name Type Description Default data str Get mse on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description mse (float) mean squared error Source code in emotioncf/cf.py def get_sub_mse ( self , data = \"all\" ): \"\"\"Calculate observed/predicted mse for each subject in matrix Args: data (str): Get mse on 'all' data, the 'training' data, or the 'test' data Returns: mse (float): mean squared error \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) mse = [] if data == \"all\" : for i in self . ratings . index : actual = self . ratings . loc [ i , :] pred = self . predicted_ratings . loc [ i , :] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) elif self . is_mask : if data == \"training\" : if self . is_mask_dilated : for i in self . masked_ratings . index : actual = self . masked_ratings . loc [ i , self . dilated_mask . loc [ i , :]] pred = self . predicted_ratings . loc [ i , self . dilated_mask . loc [ i , :] ] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) else : for i in self . ratings . index : actual = self . masked_ratings . loc [ i , self . train_mask . loc [ i , :]] pred = self . predicted_ratings . loc [ i , self . train_mask . loc [ i , :]] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) else : for i in self . ratings . index : actual = self . ratings . loc [ i , ~ self . train_mask . loc [ i , :]] pred = self . predicted_ratings . loc [ i , ~ self . train_mask . loc [ i , :]] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) else : raise ValueError ( \"Must run split_train_test() before using this option.\" ) return np . array ( mse ) plot_predictions ( self , data = 'training' , heatmapkwargs = {}) Create plot of actual and predicted ratings Parameters: Name Type Description Default data str plot 'all' data, the 'training' data, or the 'test' data 'training' Returns: Type Description r (float) Correlation Source code in emotioncf/cf.py def plot_predictions ( self , data = \"training\" , heatmapkwargs = {}): \"\"\"Create plot of actual and predicted ratings Args: data (str): plot 'all' data, the 'training' data, or the 'test' data Returns: r (float): Correlation \"\"\" import matplotlib.pyplot as plt import seaborn as sns if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) if self . is_mask : ratings = self . masked_ratings . copy () else : ratings = self . ratings . copy () heatmapkwargs . setdefault ( \"square\" , False ) heatmapkwargs . setdefault ( \"xticklabels\" , False ) heatmapkwargs . setdefault ( \"yticklabels\" , False ) vmax = ( ratings . max () . max () if ratings . max () . max () > self . predicted_ratings . max () . max () else self . predicted_ratings . max () . max () ) vmin = ( ratings . min () . min () if ratings . min () . min () < self . predicted_ratings . min () . min () else self . predicted_ratings . min () . min () ) heatmapkwargs . setdefault ( \"vmax\" , vmax ) heatmapkwargs . setdefault ( \"vmin\" , vmin ) f , ax = plt . subplots ( nrows = 1 , ncols = 3 , figsize = ( 15 , 8 )) sns . heatmap ( ratings , ax = ax [ 0 ], ** heatmapkwargs ) ax [ 0 ] . set_title ( \"Actual User/Item Ratings\" ) ax [ 0 ] . set_xlabel ( \"Items\" , fontsize = 18 ) ax [ 0 ] . set_ylabel ( \"Users\" , fontsize = 18 ) sns . heatmap ( self . predicted_ratings , ax = ax [ 1 ], ** heatmapkwargs ) ax [ 1 ] . set_title ( \"Predicted User/Item Ratings\" ) ax [ 1 ] . set_xlabel ( \"Items\" , fontsize = 18 ) ax [ 1 ] . set_ylabel ( \"Users\" , fontsize = 18 ) f . tight_layout () actual , pred = self . _retrieve_predictions ( data ) ax [ 2 ] . scatter ( actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))], pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))], ) ax [ 2 ] . set_xlabel ( \"Actual Ratings\" ) ax [ 2 ] . set_ylabel ( \"Predicted Ratings\" ) ax [ 2 ] . set_title ( \"Predicted Ratings\" ) r = self . get_corr ( data = data ) print ( \"Correlation: %s \" % r ) return f , r split_train_test ( self , n_train_items = 20 ) Split ratings matrix into train and test items. mask indicating training items Parameters: Name Type Description Default n_train_items int number of items for test dictionary or list of specific items 20 Source code in emotioncf/cf.py def split_train_test ( self , n_train_items = 20 ): \"\"\"Split ratings matrix into train and test items. mask indicating training items Args: n_train_items (int): number of items for test dictionary or list of specific items \"\"\" self . n_train_items = int ( n_train_items ) self . train_mask = self . ratings . copy () self . train_mask . loc [:, :] = np . zeros ( self . ratings . shape ) . astype ( bool ) for sub in self . ratings . index : sub_train_rating_item = np . random . choice ( self . ratings . columns , replace = False , size = n_train_items ) self . train_mask . loc [ sub , sub_train_rating_item ] = True self . masked_ratings = self . ratings [ self . train_mask ] self . is_mask = True to_long_df ( self ) Create a long format pandas dataframe with observed, predicted, and mask. Source code in emotioncf/cf.py def to_long_df ( self ): \"\"\" Create a long format pandas dataframe with observed, predicted, and mask.\"\"\" observed = pd . DataFrame ( columns = [ \"Subject\" , \"Item\" , \"Rating\" , \"Condition\" ]) for row in self . ratings . iterrows (): tmp = pd . DataFrame ( columns = observed . columns ) tmp [ \"Rating\" ] = row [ 1 ] tmp [ \"Item\" ] = self . ratings . columns tmp [ \"Subject\" ] = row [ 0 ] tmp [ \"Condition\" ] = \"Observed\" if self . is_mask : if self . is_mask_dilated : tmp [ \"Mask\" ] = self . dilated_mask . loc [ row [ 0 ]] else : tmp [ \"Mask\" ] = self . train_mask . loc [ row [ 0 ]] observed = observed . append ( tmp ) if self . is_predict : predicted = pd . DataFrame ( columns = [ \"Subject\" , \"Item\" , \"Rating\" , \"Condition\" ]) for row in self . predicted_ratings . iterrows (): tmp = pd . DataFrame ( columns = predicted . columns ) tmp [ \"Rating\" ] = row [ 1 ] tmp [ \"Item\" ] = self . predicted_ratings . columns tmp [ \"Subject\" ] = row [ 0 ] tmp [ \"Condition\" ] = \"Predicted\" if self . is_mask : tmp [ \"Mask\" ] = self . train_mask . loc [ row [ 0 ]] predicted = predicted . append ( tmp ) observed = observed . append ( predicted ) return observed KNN K-Nearest Neighbors CF algorithm fit ( self , metric = 'pearson' , dilate_ts_n_samples = None ) Fit collaborative model to training data. Calculate similarity between subjects across items Parameters: Name Type Description Default metric str type of similarity {\"pearson\",,\"spearman\",\"correlation\",\"cosine\"}. Note pearson and spearman are way faster. 'pearson' Source code in emotioncf/cf.py def fit ( self , metric = \"pearson\" , dilate_ts_n_samples = None ): \"\"\"Fit collaborative model to training data. Calculate similarity between subjects across items Args: metric (str): type of similarity {\"pearson\",,\"spearman\",\"correlation\",\"cosine\"}. Note pearson and spearman are way faster. \"\"\" if self . is_mask : ratings = self . ratings [ self . train_mask ] else : ratings = self . ratings . copy () if dilate_ts_n_samples is not None : ratings = self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) ratings = ratings [ self . dilated_mask ] def cosine_similarity ( x , y ): return np . dot ( x , y ) / ( np . linalg . norm ( x ) * np . linalg . norm ( y )) if metric in [ \"pearson\" , \"kendall\" , \"spearman\" ]: sim = ratings . T . corr ( method = metric ) elif metric in [ \"correlation\" , \"cosine\" ]: sim = pd . DataFrame ( np . zeros (( ratings . shape [ 0 ], ratings . shape [ 0 ]))) sim . columns = ratings . index sim . index = ratings . index for x in ratings . iterrows (): for y in ratings . iterrows (): if metric == \"correlation\" : sim . loc [ x [ 0 ], y [ 0 ]] = pearsonr ( x [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], y [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], )[ 0 ] elif metric == \"cosine\" : sim . loc [ x [ 0 ], y [ 0 ]] = cosine_similarity ( x [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], y [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], ) else : raise NotImplementedError ( \" %s is not implemented yet. Try ['pearson','spearman','correlation','cosine']\" % metric ) self . subject_similarity = sim self . is_fit = True predict ( self , k = None ) Predict Subject's missing items using similarity based collaborative filtering. Parameters: Name Type Description Default k int number of closest neighbors to use None Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self , k = None ): \"\"\"Predict Subject's missing items using similarity based collaborative filtering. Args: k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if self . is_mask : ratings = self . masked_ratings . copy () else : ratings = self . ratings . copy () pred = pd . DataFrame ( np . zeros ( ratings . shape )) pred . columns = ratings . columns pred . index = ratings . index for row in ratings . iterrows (): if k is not None : top_subjects = ( self . subject_similarity . loc [ row [ 0 ]] . drop ( row [ 0 ]) . sort_values ( ascending = False )[ 0 : k ] ) else : top_subjects = ( self . subject_similarity . loc [ row [ 0 ]] . drop ( row [ 0 ]) . sort_values ( ascending = False ) ) top_subjects = top_subjects [ ~ top_subjects . isnull ()] # remove nan subjects for col in ratings . iteritems (): pred . loc [ row [ 0 ], col [ 0 ]] = np . dot ( top_subjects , self . ratings . loc [ top_subjects . index , col [ 0 ]] . T ) / len ( top_subjects ) self . predicted_ratings = pred self . is_predict = True Mean CF using Item Mean across subjects fit ( self , dilate_ts_n_samples = None ) Fit collaborative model to training data. Calculate similarity between subjects across items Parameters: Name Type Description Default metric str type of similarity {\"correlation\",\"cosine\"} required dilate_ts_n_samples int will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings None Source code in emotioncf/cf.py def fit ( self , dilate_ts_n_samples = None ): \"\"\"Fit collaborative model to training data. Calculate similarity between subjects across items Args: metric (str): type of similarity {\"correlation\",\"cosine\"} dilate_ts_n_samples (int): will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings \"\"\" if self . is_mask : if dilate_ts_n_samples is not None : _ = self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) self . mean = self . masked_ratings [ self . dilated_mask ] . mean ( skipna = True , axis = 0 ) else : self . mean = self . masked_ratings [ self . train_mask ] . mean ( skipna = True , axis = 0 ) else : self . mean = self . ratings . mean ( skipna = True , axis = 0 ) self . is_fit = True predict ( self ) Predict missing items using other subject's item means. Parameters: Name Type Description Default k int number of closest neighbors to use required Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self ): \"\"\"Predict missing items using other subject's item means. Args: k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) self . predicted_ratings = self . ratings . copy () for row in self . ratings . iterrows (): self . predicted_ratings . loc [ row [ 0 ]] = self . mean self . is_predict = True NNMF_multiplicative Train non negative matrix factorization model using multiplicative updates. Allows masking to only learn the training weights. Based on http://stackoverflow.com/questions/22767695/ python-non-negative-matrix-factorization-that-handles-both-zeros-and-missing-dat fit ( self , n_factors = None , max_iterations = 100 , error_limit = 1e-06 , fit_error_limit = 1e-06 , verbose = False , dilate_ts_n_samples = None ) Fit NNMF collaborative filtering model to training data using multiplicative updating. Parameters: Name Type Description Default n_factors int Number of factors or components None max_iterations int maximum number of interations (default=100) 100 error_limit float error tolerance (default=1e-6) 1e-06 fit_error_limit float fit error tolerance (default=1e-6) 1e-06 verbose bool verbose output during fitting procedure (default=True) False dilate_ts_n_samples int will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings None Source code in emotioncf/cf.py def fit ( self , n_factors = None , max_iterations = 100 , error_limit = 1e-6 , fit_error_limit = 1e-6 , verbose = False , dilate_ts_n_samples = None , ): \"\"\"Fit NNMF collaborative filtering model to training data using multiplicative updating. Args: n_factors (int): Number of factors or components max_iterations (int): maximum number of interations (default=100) error_limit (float): error tolerance (default=1e-6) fit_error_limit (float): fit error tolerance (default=1e-6) verbose (bool): verbose output during fitting procedure (default=True) dilate_ts_n_samples (int): will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings \"\"\" eps = 1e-5 n_users , n_items = self . ratings . shape if n_factors is None : n_factors = n_items # Initial guesses for solving X ~= WH. H is random [0,1] scaled by sqrt(X.mean() / n_factors) avg = np . sqrt ( np . nanmean ( self . ratings ) / n_factors ) self . H = avg * np . random . rand ( n_items , n_factors ) # H = Y self . W = avg * np . random . rand ( n_users , n_factors ) # W = A if self . is_mask : if dilate_ts_n_samples is not None : masked_X = self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) . values mask = self . dilated_mask . values else : mask = self . train_mask . values masked_X = self . ratings . values * mask masked_X [ np . isnan ( masked_X )] = 0 else : masked_X = self . ratings . values mask = np . ones ( self . ratings . shape ) X_est_prev = np . dot ( self . W , self . H ) ctr = 1 fit_residual = 100 while ctr <= max_iterations or fit_residual < fit_error_limit : # while ctr <= max_iterations or curRes < error_limit or fit_residual < fit_error_limit: # Update W: A=A.*(((W.*X)*Y')./((W.*(A*Y))*Y')); self . W *= np . dot ( masked_X , self . H . T ) / np . dot ( mask * np . dot ( self . W , self . H ), self . H . T ) self . W = np . maximum ( self . W , eps ) # Update H: Matlab: Y=Y.*((A'*(W.*X))./(A'*(W.*(A*Y)))); self . H *= np . dot ( self . W . T , masked_X ) / np . dot ( self . W . T , mask * np . dot ( self . W , self . H ) ) self . H = np . maximum ( self . H , eps ) # Evaluate X_est = np . dot ( self . W , self . H ) err = mask * ( X_est_prev - X_est ) fit_residual = np . sqrt ( np . sum ( err ** 2 )) X_est_prev = X_est # curRes = linalg.norm(mask * (masked_X - X_est), ord='fro') if ctr % 10 == 0 and verbose : print ( \" \\t Current Iteration {} :\" . format ( ctr )) print ( \" \\t fit residual\" , np . round ( fit_residual , 4 )) # print('\\ttotal residual', np.round(curRes, 4)) ctr += 1 self . is_fit = True predict ( self ) Predict Subject's missing items using NNMF with multiplicative updating Parameters: Name Type Description Default ratings Dataframe pandas dataframe instance of ratings required k int number of closest neighbors to use required Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self ): \"\"\"Predict Subject's missing items using NNMF with multiplicative updating Args: ratings (Dataframe): pandas dataframe instance of ratings k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) self . predicted_ratings = self . ratings . copy () self . predicted_ratings . loc [:, :] = np . dot ( self . W , self . H ) self . is_predict = True NNMF_sgd Train non negative matrix factorization model using stochastic gradient descent. Allows masking to only learn the training weights. This code is based off of Ethan Rosenthal's excellent tutorial on collaborative filtering https://blog.insightdatascience.com/ explicit-matrix-factorization-als-sgd-and-all-that-jazz-b00e4d9b21ea#.kkr7mzvr2 fit ( self , n_factors = None , item_fact_reg = 0.0 , user_fact_reg = 0.0 , item_bias_reg = 0.0 , user_bias_reg = 0.0 , learning_rate = 0.001 , n_iterations = 10 , verbose = False , dilate_ts_n_samples = None ) Fit NNMF collaborative filtering model to training data using stochastic gradient descent. Parameters: Name Type Description Default n_factors int Number of factors or components None max_iterations int maximum number of interations (default=100) required error_limit float error tolerance (default=1e-6) required fit_error_limit float fit error tolerance (default=1e-6) required verbose bool verbose output during fitting procedure (default=True) False dilate_ts_n_samples int will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings None Source code in emotioncf/cf.py def fit ( self , n_factors = None , item_fact_reg = 0.0 , user_fact_reg = 0.0 , item_bias_reg = 0.0 , user_bias_reg = 0.0 , learning_rate = 0.001 , n_iterations = 10 , verbose = False , dilate_ts_n_samples = None , ): \"\"\"Fit NNMF collaborative filtering model to training data using stochastic gradient descent. Args: n_factors (int): Number of factors or components max_iterations (int): maximum number of interations (default=100) error_limit (float): error tolerance (default=1e-6) fit_error_limit (float): fit error tolerance (default=1e-6) verbose (bool): verbose output during fitting procedure (default=True) dilate_ts_n_samples (int): will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings \"\"\" # initialize variables n_users , n_items = self . ratings . shape if n_factors is None : n_factors = n_items if dilate_ts_n_samples is not None : self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) if self . is_mask : if self . is_mask_dilated : ratings = self . masked_ratings [ self . dilated_mask ] sample_row , sample_col = self . dilated_mask . values . nonzero () self . global_bias = ratings [ self . dilated_mask ] . mean () . mean () else : ratings = self . masked_ratings [ self . train_mask ] sample_row , sample_col = self . train_mask . values . nonzero () self . global_bias = ratings [ self . train_mask ] . mean () . mean () else : ratings = self . ratings . copy () sample_row , sample_col = zip ( * np . argwhere ( ~ np . isnan ( ratings . values ))) self . global_bias = ratings . values [ ~ np . isnan ( ratings . values )] . mean () # initialize latent vectors self . user_vecs = np . random . normal ( scale = 1.0 / n_factors , size = ( n_users , n_factors ) ) self . item_vecs = np . random . normal ( scale = 1.0 / n_factors , size = ( n_items , n_factors ) ) # Initialize biases self . user_bias = np . zeros ( n_users ) self . item_bias = np . zeros ( n_items ) self . item_fact_reg = item_fact_reg self . user_fact_reg = user_fact_reg self . item_bias_reg = item_bias_reg self . user_bias_reg = user_bias_reg # train weights ctr = 1 while ctr <= n_iterations : if ctr % 10 == 0 and verbose : print ( \" \\t Current Iteration: {} \" . format ( ctr )) training_indices = np . arange ( len ( sample_row )) np . random . shuffle ( training_indices ) for idx in training_indices : u = sample_row [ idx ] i = sample_col [ idx ] prediction = self . _predict_single ( u , i ) e = ratings . iloc [ u , i ] - prediction # error # Update biases self . user_bias [ u ] += learning_rate * ( e - self . user_bias_reg * self . user_bias [ u ] ) self . item_bias [ i ] += learning_rate * ( e - self . item_bias_reg * self . item_bias [ i ] ) # Update latent factors self . user_vecs [ u , :] += learning_rate * ( e * self . item_vecs [ i , :] - self . user_fact_reg * self . user_vecs [ u , :] ) self . item_vecs [ i , :] += learning_rate * ( e * self . user_vecs [ u , :] - self . item_fact_reg * self . item_vecs [ i , :] ) ctr += 1 self . is_fit = True predict ( self ) Predict Subject's missing items using NNMF with stochastic gradient descent Parameters: Name Type Description Default ratings Dataframe pandas dataframe instance of ratings required k int number of closest neighbors to use required Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self ): \"\"\"Predict Subject's missing items using NNMF with stochastic gradient descent Args: ratings (Dataframe): pandas dataframe instance of ratings k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" self . predicted_ratings = self . ratings . copy () for u in range ( self . user_vecs . shape [ 0 ]): for i in range ( self . item_vecs . shape [ 0 ]): self . predicted_ratings . iloc [ u , i ] = self . _predict_single ( u , i ) self . is_predict = True","title":"cf"},{"location":"api/cf/#cf","text":"","title":"cf"},{"location":"api/cf/#emotioncf.cf","text":"Classes that perform various types of collaborative filtering","title":"emotioncf.cf"},{"location":"api/cf/#emotioncf.cf.BaseCF","text":"Base Collaborative Filtering Class","title":"BaseCF"},{"location":"api/cf/#emotioncf.cf.BaseCF.downsample","text":"Downsample rating matrix to a new target frequency or number of samples using averaging. Parameters: Name Type Description Default sampling_freq int/float Sampling frequency of data None target int/float downsampling target None target_type str type of target can be [samples,seconds,hz] 'samples' Source code in emotioncf/cf.py def downsample ( self , sampling_freq = None , target = None , target_type = \"samples\" ): \"\"\"Downsample rating matrix to a new target frequency or number of samples using averaging. Args: sampling_freq (int/float): Sampling frequency of data target (int/float): downsampling target target_type (str): type of target can be [samples,seconds,hz] \"\"\" if sampling_freq is None : raise ValueError ( \"Please specify the sampling frequency of the ratings data.\" ) if target is None : raise ValueError ( \"Please specify the downsampling target.\" ) if target_type is None : raise ValueError ( \"Please specify the type of target to downsample to [samples,seconds,hz].\" ) def ds ( ratings , sampling_freq = sampling_freq , target = None , target_type = \"samples\" ): if target_type == \"samples\" : n_samples = target elif target_type == \"seconds\" : n_samples = target * sampling_freq elif target_type == \"hz\" : n_samples = sampling_freq / target else : raise ValueError ( 'Make sure target_type is \"samples\", \"seconds\", or \"hz\".' ) ratings = ratings . T idx = np . sort ( np . repeat ( np . arange ( 1 , ratings . shape [ 0 ] / n_samples , 1 ), n_samples ) ) if ratings . shape [ 0 ] > len ( idx ): idx = np . concatenate ( [ idx , np . repeat ( idx [ - 1 ] + 1 , ratings . shape [ 0 ] - len ( idx ))] ) return ratings . groupby ( idx ) . mean () . T self . ratings = ds ( self . ratings , sampling_freq = sampling_freq , target = target , target_type = target_type , ) if self . is_mask : self . train_mask = ds ( self . train_mask , sampling_freq = sampling_freq , target = target , target_type = target_type , ) self . train_mask . loc [:, :] = self . train_mask > 0 self . masked_ratings = ds ( self . masked_ratings , sampling_freq = sampling_freq , target = target , target_type = target_type , ) if self . is_mask_dilated : self . dilated_mask = ds ( self . dilated_mask , sampling_freq = sampling_freq , target = target , target_type = target_type , ) self . dilated_mask . loc [:, :] = self . dilated_mask > 0 if self . is_predict : self . predicted_ratings = ds ( self . predicted_ratings , sampling_freq = sampling_freq , target = target , target_type = target_type , )","title":"downsample()"},{"location":"api/cf/#emotioncf.cf.BaseCF.get_corr","text":"Get overall correlation for predicted compared to actual for all items and subjects. Parameters: Name Type Description Default data str Get correlation on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description r (float) Correlation Source code in emotioncf/cf.py def get_corr ( self , data = \"all\" ): \"\"\"Get overall correlation for predicted compared to actual for all items and subjects. Args: data (str): Get correlation on 'all' data, the 'training' data, or the 'test' data Returns: r (float): Correlation \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) actual , pred = self . _retrieve_predictions ( data ) return pearsonr ( actual , pred )[ 0 ]","title":"get_corr()"},{"location":"api/cf/#emotioncf.cf.BaseCF.get_mse","text":"Get overall mean squared error for predicted compared to actual for all items and subjects. Parameters: Name Type Description Default data str Get mse on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description mse (float) mean squared error Source code in emotioncf/cf.py def get_mse ( self , data = \"all\" ): \"\"\"Get overall mean squared error for predicted compared to actual for all items and subjects. Args: data (str): Get mse on 'all' data, the 'training' data, or the 'test' data Returns: mse (float): mean squared error \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) actual , pred = self . _retrieve_predictions ( data ) return np . mean (( pred - actual ) ** 2 )","title":"get_mse()"},{"location":"api/cf/#emotioncf.cf.BaseCF.get_sub_corr","text":"Calculate observed/predicted correlation for each subject in matrix Parameters: Name Type Description Default data str Get correlation on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description r (float) Correlation Source code in emotioncf/cf.py def get_sub_corr ( self , data = \"all\" ): \"\"\"Calculate observed/predicted correlation for each subject in matrix Args: data (str): Get correlation on 'all' data, the 'training' data, or the 'test' data Returns: r (float): Correlation \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) r = [] # Note: the following mask prevents NaN values from being passed to `pearsonr()`. # However, it does not guaratee that no correlation values will be NaN, e.g. if only one # rating for a given subject is non-null in both test and train groups for a given # dataset, or variance is otherwise zero. if data == \"all\" : noNanMask = ( ~ np . isnan ( self . ratings )) & ( ~ np . isnan ( self . predicted_ratings )) for i in self . ratings . index : r . append ( pearsonr ( self . ratings . loc [ i , :][ noNanMask . loc [ i , :]], self . predicted_ratings . loc [ i , :][ noNanMask . loc [ i , :]], )[ 0 ] ) elif self . is_mask : if data == \"training\" : noNanMask = ( ~ np . isnan ( self . masked_ratings )) & ( ~ np . isnan ( self . predicted_ratings ) ) if self . is_mask_dilated : for i in self . masked_ratings . index : r . append ( pearsonr ( self . masked_ratings . loc [ i , self . dilated_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], self . predicted_ratings . loc [ i , self . dilated_mask . loc [ i , :] ][ noNanMask . loc [ i , :]], )[ 0 ] ) else : for i in self . masked_ratings . index : r . append ( pearsonr ( self . masked_ratings . loc [ i , self . train_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], self . predicted_ratings . loc [ i , self . train_mask . loc [ i , :] ][ noNanMask . loc [ i , :]], )[ 0 ] ) else : # test noNanMask = ( ~ np . isnan ( self . ratings )) & ( ~ np . isnan ( self . predicted_ratings ) ) for i in self . masked_ratings . index : r . append ( pearsonr ( self . ratings . loc [ i , ~ self . train_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], self . predicted_ratings . loc [ i , ~ self . train_mask . loc [ i , :]][ noNanMask . loc [ i , :] ], )[ 0 ] ) else : raise ValueError ( \"Must run split_train_test() before using this option.\" ) return np . array ( r )","title":"get_sub_corr()"},{"location":"api/cf/#emotioncf.cf.BaseCF.get_sub_mse","text":"Calculate observed/predicted mse for each subject in matrix Parameters: Name Type Description Default data str Get mse on 'all' data, the 'training' data, or the 'test' data 'all' Returns: Type Description mse (float) mean squared error Source code in emotioncf/cf.py def get_sub_mse ( self , data = \"all\" ): \"\"\"Calculate observed/predicted mse for each subject in matrix Args: data (str): Get mse on 'all' data, the 'training' data, or the 'test' data Returns: mse (float): mean squared error \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) mse = [] if data == \"all\" : for i in self . ratings . index : actual = self . ratings . loc [ i , :] pred = self . predicted_ratings . loc [ i , :] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) elif self . is_mask : if data == \"training\" : if self . is_mask_dilated : for i in self . masked_ratings . index : actual = self . masked_ratings . loc [ i , self . dilated_mask . loc [ i , :]] pred = self . predicted_ratings . loc [ i , self . dilated_mask . loc [ i , :] ] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) else : for i in self . ratings . index : actual = self . masked_ratings . loc [ i , self . train_mask . loc [ i , :]] pred = self . predicted_ratings . loc [ i , self . train_mask . loc [ i , :]] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) else : for i in self . ratings . index : actual = self . ratings . loc [ i , ~ self . train_mask . loc [ i , :]] pred = self . predicted_ratings . loc [ i , ~ self . train_mask . loc [ i , :]] mse . append ( np . mean ( ( pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] - actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))] ) ** 2 ) ) else : raise ValueError ( \"Must run split_train_test() before using this option.\" ) return np . array ( mse )","title":"get_sub_mse()"},{"location":"api/cf/#emotioncf.cf.BaseCF.plot_predictions","text":"Create plot of actual and predicted ratings Parameters: Name Type Description Default data str plot 'all' data, the 'training' data, or the 'test' data 'training' Returns: Type Description r (float) Correlation Source code in emotioncf/cf.py def plot_predictions ( self , data = \"training\" , heatmapkwargs = {}): \"\"\"Create plot of actual and predicted ratings Args: data (str): plot 'all' data, the 'training' data, or the 'test' data Returns: r (float): Correlation \"\"\" import matplotlib.pyplot as plt import seaborn as sns if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if not self . is_predict : raise ValueError ( \"You must predict() model first before using this method.\" ) if self . is_mask : ratings = self . masked_ratings . copy () else : ratings = self . ratings . copy () heatmapkwargs . setdefault ( \"square\" , False ) heatmapkwargs . setdefault ( \"xticklabels\" , False ) heatmapkwargs . setdefault ( \"yticklabels\" , False ) vmax = ( ratings . max () . max () if ratings . max () . max () > self . predicted_ratings . max () . max () else self . predicted_ratings . max () . max () ) vmin = ( ratings . min () . min () if ratings . min () . min () < self . predicted_ratings . min () . min () else self . predicted_ratings . min () . min () ) heatmapkwargs . setdefault ( \"vmax\" , vmax ) heatmapkwargs . setdefault ( \"vmin\" , vmin ) f , ax = plt . subplots ( nrows = 1 , ncols = 3 , figsize = ( 15 , 8 )) sns . heatmap ( ratings , ax = ax [ 0 ], ** heatmapkwargs ) ax [ 0 ] . set_title ( \"Actual User/Item Ratings\" ) ax [ 0 ] . set_xlabel ( \"Items\" , fontsize = 18 ) ax [ 0 ] . set_ylabel ( \"Users\" , fontsize = 18 ) sns . heatmap ( self . predicted_ratings , ax = ax [ 1 ], ** heatmapkwargs ) ax [ 1 ] . set_title ( \"Predicted User/Item Ratings\" ) ax [ 1 ] . set_xlabel ( \"Items\" , fontsize = 18 ) ax [ 1 ] . set_ylabel ( \"Users\" , fontsize = 18 ) f . tight_layout () actual , pred = self . _retrieve_predictions ( data ) ax [ 2 ] . scatter ( actual [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))], pred [( ~ np . isnan ( actual )) & ( ~ np . isnan ( pred ))], ) ax [ 2 ] . set_xlabel ( \"Actual Ratings\" ) ax [ 2 ] . set_ylabel ( \"Predicted Ratings\" ) ax [ 2 ] . set_title ( \"Predicted Ratings\" ) r = self . get_corr ( data = data ) print ( \"Correlation: %s \" % r ) return f , r","title":"plot_predictions()"},{"location":"api/cf/#emotioncf.cf.BaseCF.split_train_test","text":"Split ratings matrix into train and test items. mask indicating training items Parameters: Name Type Description Default n_train_items int number of items for test dictionary or list of specific items 20 Source code in emotioncf/cf.py def split_train_test ( self , n_train_items = 20 ): \"\"\"Split ratings matrix into train and test items. mask indicating training items Args: n_train_items (int): number of items for test dictionary or list of specific items \"\"\" self . n_train_items = int ( n_train_items ) self . train_mask = self . ratings . copy () self . train_mask . loc [:, :] = np . zeros ( self . ratings . shape ) . astype ( bool ) for sub in self . ratings . index : sub_train_rating_item = np . random . choice ( self . ratings . columns , replace = False , size = n_train_items ) self . train_mask . loc [ sub , sub_train_rating_item ] = True self . masked_ratings = self . ratings [ self . train_mask ] self . is_mask = True","title":"split_train_test()"},{"location":"api/cf/#emotioncf.cf.BaseCF.to_long_df","text":"Create a long format pandas dataframe with observed, predicted, and mask. Source code in emotioncf/cf.py def to_long_df ( self ): \"\"\" Create a long format pandas dataframe with observed, predicted, and mask.\"\"\" observed = pd . DataFrame ( columns = [ \"Subject\" , \"Item\" , \"Rating\" , \"Condition\" ]) for row in self . ratings . iterrows (): tmp = pd . DataFrame ( columns = observed . columns ) tmp [ \"Rating\" ] = row [ 1 ] tmp [ \"Item\" ] = self . ratings . columns tmp [ \"Subject\" ] = row [ 0 ] tmp [ \"Condition\" ] = \"Observed\" if self . is_mask : if self . is_mask_dilated : tmp [ \"Mask\" ] = self . dilated_mask . loc [ row [ 0 ]] else : tmp [ \"Mask\" ] = self . train_mask . loc [ row [ 0 ]] observed = observed . append ( tmp ) if self . is_predict : predicted = pd . DataFrame ( columns = [ \"Subject\" , \"Item\" , \"Rating\" , \"Condition\" ]) for row in self . predicted_ratings . iterrows (): tmp = pd . DataFrame ( columns = predicted . columns ) tmp [ \"Rating\" ] = row [ 1 ] tmp [ \"Item\" ] = self . predicted_ratings . columns tmp [ \"Subject\" ] = row [ 0 ] tmp [ \"Condition\" ] = \"Predicted\" if self . is_mask : tmp [ \"Mask\" ] = self . train_mask . loc [ row [ 0 ]] predicted = predicted . append ( tmp ) observed = observed . append ( predicted ) return observed","title":"to_long_df()"},{"location":"api/cf/#emotioncf.cf.KNN","text":"K-Nearest Neighbors CF algorithm","title":"KNN"},{"location":"api/cf/#emotioncf.cf.KNN.fit","text":"Fit collaborative model to training data. Calculate similarity between subjects across items Parameters: Name Type Description Default metric str type of similarity {\"pearson\",,\"spearman\",\"correlation\",\"cosine\"}. Note pearson and spearman are way faster. 'pearson' Source code in emotioncf/cf.py def fit ( self , metric = \"pearson\" , dilate_ts_n_samples = None ): \"\"\"Fit collaborative model to training data. Calculate similarity between subjects across items Args: metric (str): type of similarity {\"pearson\",,\"spearman\",\"correlation\",\"cosine\"}. Note pearson and spearman are way faster. \"\"\" if self . is_mask : ratings = self . ratings [ self . train_mask ] else : ratings = self . ratings . copy () if dilate_ts_n_samples is not None : ratings = self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) ratings = ratings [ self . dilated_mask ] def cosine_similarity ( x , y ): return np . dot ( x , y ) / ( np . linalg . norm ( x ) * np . linalg . norm ( y )) if metric in [ \"pearson\" , \"kendall\" , \"spearman\" ]: sim = ratings . T . corr ( method = metric ) elif metric in [ \"correlation\" , \"cosine\" ]: sim = pd . DataFrame ( np . zeros (( ratings . shape [ 0 ], ratings . shape [ 0 ]))) sim . columns = ratings . index sim . index = ratings . index for x in ratings . iterrows (): for y in ratings . iterrows (): if metric == \"correlation\" : sim . loc [ x [ 0 ], y [ 0 ]] = pearsonr ( x [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], y [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], )[ 0 ] elif metric == \"cosine\" : sim . loc [ x [ 0 ], y [ 0 ]] = cosine_similarity ( x [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], y [ 1 ][( ~ x [ 1 ] . isnull ()) & ( ~ y [ 1 ] . isnull ())], ) else : raise NotImplementedError ( \" %s is not implemented yet. Try ['pearson','spearman','correlation','cosine']\" % metric ) self . subject_similarity = sim self . is_fit = True","title":"fit()"},{"location":"api/cf/#emotioncf.cf.KNN.predict","text":"Predict Subject's missing items using similarity based collaborative filtering. Parameters: Name Type Description Default k int number of closest neighbors to use None Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self , k = None ): \"\"\"Predict Subject's missing items using similarity based collaborative filtering. Args: k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) if self . is_mask : ratings = self . masked_ratings . copy () else : ratings = self . ratings . copy () pred = pd . DataFrame ( np . zeros ( ratings . shape )) pred . columns = ratings . columns pred . index = ratings . index for row in ratings . iterrows (): if k is not None : top_subjects = ( self . subject_similarity . loc [ row [ 0 ]] . drop ( row [ 0 ]) . sort_values ( ascending = False )[ 0 : k ] ) else : top_subjects = ( self . subject_similarity . loc [ row [ 0 ]] . drop ( row [ 0 ]) . sort_values ( ascending = False ) ) top_subjects = top_subjects [ ~ top_subjects . isnull ()] # remove nan subjects for col in ratings . iteritems (): pred . loc [ row [ 0 ], col [ 0 ]] = np . dot ( top_subjects , self . ratings . loc [ top_subjects . index , col [ 0 ]] . T ) / len ( top_subjects ) self . predicted_ratings = pred self . is_predict = True","title":"predict()"},{"location":"api/cf/#emotioncf.cf.Mean","text":"CF using Item Mean across subjects","title":"Mean"},{"location":"api/cf/#emotioncf.cf.Mean.fit","text":"Fit collaborative model to training data. Calculate similarity between subjects across items Parameters: Name Type Description Default metric str type of similarity {\"correlation\",\"cosine\"} required dilate_ts_n_samples int will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings None Source code in emotioncf/cf.py def fit ( self , dilate_ts_n_samples = None ): \"\"\"Fit collaborative model to training data. Calculate similarity between subjects across items Args: metric (str): type of similarity {\"correlation\",\"cosine\"} dilate_ts_n_samples (int): will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings \"\"\" if self . is_mask : if dilate_ts_n_samples is not None : _ = self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) self . mean = self . masked_ratings [ self . dilated_mask ] . mean ( skipna = True , axis = 0 ) else : self . mean = self . masked_ratings [ self . train_mask ] . mean ( skipna = True , axis = 0 ) else : self . mean = self . ratings . mean ( skipna = True , axis = 0 ) self . is_fit = True","title":"fit()"},{"location":"api/cf/#emotioncf.cf.Mean.predict","text":"Predict missing items using other subject's item means. Parameters: Name Type Description Default k int number of closest neighbors to use required Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self ): \"\"\"Predict missing items using other subject's item means. Args: k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) self . predicted_ratings = self . ratings . copy () for row in self . ratings . iterrows (): self . predicted_ratings . loc [ row [ 0 ]] = self . mean self . is_predict = True","title":"predict()"},{"location":"api/cf/#emotioncf.cf.NNMF_multiplicative","text":"Train non negative matrix factorization model using multiplicative updates. Allows masking to only learn the training weights. Based on http://stackoverflow.com/questions/22767695/ python-non-negative-matrix-factorization-that-handles-both-zeros-and-missing-dat","title":"NNMF_multiplicative"},{"location":"api/cf/#emotioncf.cf.NNMF_multiplicative.fit","text":"Fit NNMF collaborative filtering model to training data using multiplicative updating. Parameters: Name Type Description Default n_factors int Number of factors or components None max_iterations int maximum number of interations (default=100) 100 error_limit float error tolerance (default=1e-6) 1e-06 fit_error_limit float fit error tolerance (default=1e-6) 1e-06 verbose bool verbose output during fitting procedure (default=True) False dilate_ts_n_samples int will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings None Source code in emotioncf/cf.py def fit ( self , n_factors = None , max_iterations = 100 , error_limit = 1e-6 , fit_error_limit = 1e-6 , verbose = False , dilate_ts_n_samples = None , ): \"\"\"Fit NNMF collaborative filtering model to training data using multiplicative updating. Args: n_factors (int): Number of factors or components max_iterations (int): maximum number of interations (default=100) error_limit (float): error tolerance (default=1e-6) fit_error_limit (float): fit error tolerance (default=1e-6) verbose (bool): verbose output during fitting procedure (default=True) dilate_ts_n_samples (int): will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings \"\"\" eps = 1e-5 n_users , n_items = self . ratings . shape if n_factors is None : n_factors = n_items # Initial guesses for solving X ~= WH. H is random [0,1] scaled by sqrt(X.mean() / n_factors) avg = np . sqrt ( np . nanmean ( self . ratings ) / n_factors ) self . H = avg * np . random . rand ( n_items , n_factors ) # H = Y self . W = avg * np . random . rand ( n_users , n_factors ) # W = A if self . is_mask : if dilate_ts_n_samples is not None : masked_X = self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) . values mask = self . dilated_mask . values else : mask = self . train_mask . values masked_X = self . ratings . values * mask masked_X [ np . isnan ( masked_X )] = 0 else : masked_X = self . ratings . values mask = np . ones ( self . ratings . shape ) X_est_prev = np . dot ( self . W , self . H ) ctr = 1 fit_residual = 100 while ctr <= max_iterations or fit_residual < fit_error_limit : # while ctr <= max_iterations or curRes < error_limit or fit_residual < fit_error_limit: # Update W: A=A.*(((W.*X)*Y')./((W.*(A*Y))*Y')); self . W *= np . dot ( masked_X , self . H . T ) / np . dot ( mask * np . dot ( self . W , self . H ), self . H . T ) self . W = np . maximum ( self . W , eps ) # Update H: Matlab: Y=Y.*((A'*(W.*X))./(A'*(W.*(A*Y)))); self . H *= np . dot ( self . W . T , masked_X ) / np . dot ( self . W . T , mask * np . dot ( self . W , self . H ) ) self . H = np . maximum ( self . H , eps ) # Evaluate X_est = np . dot ( self . W , self . H ) err = mask * ( X_est_prev - X_est ) fit_residual = np . sqrt ( np . sum ( err ** 2 )) X_est_prev = X_est # curRes = linalg.norm(mask * (masked_X - X_est), ord='fro') if ctr % 10 == 0 and verbose : print ( \" \\t Current Iteration {} :\" . format ( ctr )) print ( \" \\t fit residual\" , np . round ( fit_residual , 4 )) # print('\\ttotal residual', np.round(curRes, 4)) ctr += 1 self . is_fit = True","title":"fit()"},{"location":"api/cf/#emotioncf.cf.NNMF_multiplicative.predict","text":"Predict Subject's missing items using NNMF with multiplicative updating Parameters: Name Type Description Default ratings Dataframe pandas dataframe instance of ratings required k int number of closest neighbors to use required Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self ): \"\"\"Predict Subject's missing items using NNMF with multiplicative updating Args: ratings (Dataframe): pandas dataframe instance of ratings k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" if not self . is_fit : raise ValueError ( \"You must fit() model first before using this method.\" ) self . predicted_ratings = self . ratings . copy () self . predicted_ratings . loc [:, :] = np . dot ( self . W , self . H ) self . is_predict = True","title":"predict()"},{"location":"api/cf/#emotioncf.cf.NNMF_sgd","text":"Train non negative matrix factorization model using stochastic gradient descent. Allows masking to only learn the training weights. This code is based off of Ethan Rosenthal's excellent tutorial on collaborative filtering https://blog.insightdatascience.com/ explicit-matrix-factorization-als-sgd-and-all-that-jazz-b00e4d9b21ea#.kkr7mzvr2","title":"NNMF_sgd"},{"location":"api/cf/#emotioncf.cf.NNMF_sgd.fit","text":"Fit NNMF collaborative filtering model to training data using stochastic gradient descent. Parameters: Name Type Description Default n_factors int Number of factors or components None max_iterations int maximum number of interations (default=100) required error_limit float error tolerance (default=1e-6) required fit_error_limit float fit error tolerance (default=1e-6) required verbose bool verbose output during fitting procedure (default=True) False dilate_ts_n_samples int will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings None Source code in emotioncf/cf.py def fit ( self , n_factors = None , item_fact_reg = 0.0 , user_fact_reg = 0.0 , item_bias_reg = 0.0 , user_bias_reg = 0.0 , learning_rate = 0.001 , n_iterations = 10 , verbose = False , dilate_ts_n_samples = None , ): \"\"\"Fit NNMF collaborative filtering model to training data using stochastic gradient descent. Args: n_factors (int): Number of factors or components max_iterations (int): maximum number of interations (default=100) error_limit (float): error tolerance (default=1e-6) fit_error_limit (float): fit error tolerance (default=1e-6) verbose (bool): verbose output during fitting procedure (default=True) dilate_ts_n_samples (int): will dilate masked samples by n_samples to leverage auto-correlation in estimating time-series ratings \"\"\" # initialize variables n_users , n_items = self . ratings . shape if n_factors is None : n_factors = n_items if dilate_ts_n_samples is not None : self . _dilate_ts_rating_samples ( n_samples = dilate_ts_n_samples ) if self . is_mask : if self . is_mask_dilated : ratings = self . masked_ratings [ self . dilated_mask ] sample_row , sample_col = self . dilated_mask . values . nonzero () self . global_bias = ratings [ self . dilated_mask ] . mean () . mean () else : ratings = self . masked_ratings [ self . train_mask ] sample_row , sample_col = self . train_mask . values . nonzero () self . global_bias = ratings [ self . train_mask ] . mean () . mean () else : ratings = self . ratings . copy () sample_row , sample_col = zip ( * np . argwhere ( ~ np . isnan ( ratings . values ))) self . global_bias = ratings . values [ ~ np . isnan ( ratings . values )] . mean () # initialize latent vectors self . user_vecs = np . random . normal ( scale = 1.0 / n_factors , size = ( n_users , n_factors ) ) self . item_vecs = np . random . normal ( scale = 1.0 / n_factors , size = ( n_items , n_factors ) ) # Initialize biases self . user_bias = np . zeros ( n_users ) self . item_bias = np . zeros ( n_items ) self . item_fact_reg = item_fact_reg self . user_fact_reg = user_fact_reg self . item_bias_reg = item_bias_reg self . user_bias_reg = user_bias_reg # train weights ctr = 1 while ctr <= n_iterations : if ctr % 10 == 0 and verbose : print ( \" \\t Current Iteration: {} \" . format ( ctr )) training_indices = np . arange ( len ( sample_row )) np . random . shuffle ( training_indices ) for idx in training_indices : u = sample_row [ idx ] i = sample_col [ idx ] prediction = self . _predict_single ( u , i ) e = ratings . iloc [ u , i ] - prediction # error # Update biases self . user_bias [ u ] += learning_rate * ( e - self . user_bias_reg * self . user_bias [ u ] ) self . item_bias [ i ] += learning_rate * ( e - self . item_bias_reg * self . item_bias [ i ] ) # Update latent factors self . user_vecs [ u , :] += learning_rate * ( e * self . item_vecs [ i , :] - self . user_fact_reg * self . user_vecs [ u , :] ) self . item_vecs [ i , :] += learning_rate * ( e * self . user_vecs [ u , :] - self . item_fact_reg * self . item_vecs [ i , :] ) ctr += 1 self . is_fit = True","title":"fit()"},{"location":"api/cf/#emotioncf.cf.NNMF_sgd.predict","text":"Predict Subject's missing items using NNMF with stochastic gradient descent Parameters: Name Type Description Default ratings Dataframe pandas dataframe instance of ratings required k int number of closest neighbors to use required Returns: Type Description predicted_rating (Dataframe) adds field to object instance Source code in emotioncf/cf.py def predict ( self ): \"\"\"Predict Subject's missing items using NNMF with stochastic gradient descent Args: ratings (Dataframe): pandas dataframe instance of ratings k (int): number of closest neighbors to use Returns: predicted_rating (Dataframe): adds field to object instance \"\"\" self . predicted_ratings = self . ratings . copy () for u in range ( self . user_vecs . shape [ 0 ]): for i in range ( self . item_vecs . shape [ 0 ]): self . predicted_ratings . iloc [ u , i ] = self . _predict_single ( u , i ) self . is_predict = True","title":"predict()"},{"location":"api/data/","text":"Functions that perform various data transformations create_sub_by_item_matrix ( df ) Convert a pandas long data frame of a single rating into a subject by item matrix Parameters: Name Type Description Default df Dataframe input dataframe. Must have columns [\"Subject\", \"Item\", \"Rating\"] required Source code in emotioncf/data.py def create_sub_by_item_matrix ( df ): \"\"\"Convert a pandas long data frame of a single rating into a subject by item matrix Args: df (Dataframe): input dataframe. Must have columns [\"Subject\", \"Item\", \"Rating\"] \"\"\" if not isinstance ( df , pd . DataFrame ): raise ValueError ( \"df must be pandas instance\" ) if not all ([ x in df . columns for x in [ \"Subject\" , \"Item\" , \"Rating\" ]]): raise ValueError ( \"df must contain ['Subject','Item','Rating] as column names\" ) ratings = df . pivot ( index = \"Subject\" , columns = \"Item\" , values = \"Rating\" ) . reset_index ( drop = True ) return ratings . astype ( float )","title":"data"},{"location":"api/data/#emotioncf.data","text":"Functions that perform various data transformations","title":"emotioncf.data"},{"location":"api/data/#emotioncf.data.create_sub_by_item_matrix","text":"Convert a pandas long data frame of a single rating into a subject by item matrix Parameters: Name Type Description Default df Dataframe input dataframe. Must have columns [\"Subject\", \"Item\", \"Rating\"] required Source code in emotioncf/data.py def create_sub_by_item_matrix ( df ): \"\"\"Convert a pandas long data frame of a single rating into a subject by item matrix Args: df (Dataframe): input dataframe. Must have columns [\"Subject\", \"Item\", \"Rating\"] \"\"\" if not isinstance ( df , pd . DataFrame ): raise ValueError ( \"df must be pandas instance\" ) if not all ([ x in df . columns for x in [ \"Subject\" , \"Item\" , \"Rating\" ]]): raise ValueError ( \"df must contain ['Subject','Item','Rating] as column names\" ) ratings = df . pivot ( index = \"Subject\" , columns = \"Item\" , values = \"Rating\" ) . reset_index ( drop = True ) return ratings . astype ( float )","title":"create_sub_by_item_matrix()"}]}